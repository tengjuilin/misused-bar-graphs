{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b077b0b-d91e-4aad-ab2e-20905da76ed2",
   "metadata": {},
   "source": [
    "# Bar Graph Classification\n",
    "\n",
    "Teng-Jui Lin\n",
    "\n",
    "- Created: 2023-05-27\n",
    "- Edited: 2024-09-28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5098e217-5498-4f00-9f8e-36a56181e029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bar_constants import *\n",
    "set_save_fig_rc()\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23c31dd-3791-42e2-8483-14bdd825f4e2",
   "metadata": {},
   "source": [
    "## Calculate article statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e86738-5b5b-4c1d-9d09-5f5d73898144",
   "metadata": {},
   "source": [
    "### Import Zotero article data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6c0ad7-592d-4ddd-97f3-71d681e19b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zotero article data\n",
    "articles_df = pd.DataFrame()\n",
    "for i, journal in enumerate(JOURNALS):\n",
    "    filename = os.path.join(ZOTERO_PATH, f'{journal}.csv')\n",
    "    articles_df_ = pd.read_csv(filename)\n",
    "    articles_df = pd.concat([articles_df, articles_df_])\n",
    "articles_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64361f75-9caf-4dbb-8cda-6c5ddf521680",
   "metadata": {},
   "source": [
    "### Calculate number of authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3919d4-84e4-485b-91e1-aa644325eabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract individual authors\n",
    "authors_df_ = articles_df['Author'].str.split(';', expand=True)\n",
    "# calculate number of authors\n",
    "num_authors_series = (~pd.isna(authors_df_)).sum(axis=1)\n",
    "articles_df[NUM_AUTHORS_LABEL] = num_authors_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006914b9-ab0e-4bc9-947d-d5ee19bdda7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract individual word in title\n",
    "NUM_WORDS_TITLE_LABEL = 'Title Word Count'\n",
    "title_df_ = articles_df['Title'].str.split(' ', expand=True)\n",
    "# calculate number of words in title\n",
    "title_series = (~pd.isna(title_df_)).sum(axis=1)\n",
    "articles_df[NUM_WORDS_TITLE_LABEL] = title_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1e53ac-bc04-47f6-b7ad-9e8b5301ab0c",
   "metadata": {},
   "source": [
    "### Add article statistics labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99155e5d-6e9b-4dd9-bb8c-6c86f1a2f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_boolean(df, regex, label, assigned_bool):\n",
    "    df.loc[df[MANUAL_TAGS_LABEL].str.contains(regex), label] = assigned_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d46f9d-730b-494b-8eca-48c8d540dbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutually exclusive label: does the article has at least 1 bar graph\n",
    "articles_df[HAS_BAR_GRAPH_LABEL] = True\n",
    "assign_boolean(articles_df, NO_BAR_GRAPH_REGEX_LABEL, HAS_BAR_GRAPH_LABEL, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71f54df-9eed-42a3-aeef-95ac1ef7d906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutually exclusive label: does the article has at least 1 inaccurate bar graph\n",
    "# separated into two columns because have articles with no bar graph\n",
    "articles_df[NO_MISUSE_LABEL] = False\n",
    "articles_df[HAS_MISUSE_LABEL] = False\n",
    "assign_boolean(articles_df, NO_MISUSE_REGEX_LABEL, NO_MISUSE_LABEL, True)\n",
    "assign_boolean(articles_df, HAS_MISUSE_REGEX_LABEL, HAS_MISUSE_LABEL, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c71b7e9-e2e4-4e03-b8e5-494b55ffdf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-mutually exclusive labels with one hot encoding\n",
    "# log, zero, others\n",
    "articles_df[ZERO_PROBLEM_LABEL] = False\n",
    "articles_df[LOG_PROBLEM_LABEL] = False\n",
    "articles_df[OTHER_PROBLEM_LABEL] = False\n",
    "assign_boolean(articles_df, ZERO_PROBLEM_REGEX_LABEL, ZERO_PROBLEM_LABEL, True)\n",
    "assign_boolean(articles_df, LOG_PROBLEM_REGEX_LABEL, LOG_PROBLEM_LABEL, True)\n",
    "assign_boolean(articles_df, OTHER_PROBLEM_REGEX_LABEL, OTHER_PROBLEM_LABEL, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69b4c3f-6ef0-4ce3-b33b-01ea84801661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save raw data to csv\n",
    "articles_df.to_csv(articles_df_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c2a70-00bd-481a-a9cc-c887a4c32086",
   "metadata": {},
   "source": [
    "### Calculate cumulative article statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c3782e-209f-4088-aa68-7288484c30b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_stats(df, cond):\n",
    "    return df[cond].groupby(PUBLICATION_LABEL).count().iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31da2345-f02b-4ea2-9234-6bc0a3ad9a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_stat_df = pd.DataFrame()\n",
    "articles_stat_df[NUM_ARTICLES_LABEL] = articles_df.groupby(PUBLICATION_LABEL).count().iloc[:, 0]\n",
    "articles_stat_df[NUM_ARTICLES_WITH_BAR_GRAPH_LABEL] = get_article_stats(articles_df, articles_df[HAS_BAR_GRAPH_LABEL] == True)\n",
    "articles_stat_df[NUM_ARTICLES_WITHOUT_BAR_GRAPH_LABEL] = get_article_stats(articles_df, ~articles_df[HAS_BAR_GRAPH_LABEL] == True)\n",
    "articles_stat_df[NUM_ARTICLES_CORRECT_BAR_GRAPH_LABEL] = get_article_stats(articles_df, articles_df[NO_MISUSE_LABEL] == True)\n",
    "articles_stat_df[NUM_ARTICLES_INCORRECT_BAR_GRAPH_LABEL] = get_article_stats(articles_df, articles_df[HAS_MISUSE_LABEL] == True)\n",
    "articles_stat_df[NUM_ARTICLES_ZERO_PROBLEM_LABEL] = get_article_stats(articles_df, articles_df[ZERO_PROBLEM_LABEL] == True)\n",
    "articles_stat_df[NUM_ARTICLES_LOG_PROBLEM_LABEL] = get_article_stats(articles_df, articles_df[LOG_PROBLEM_LABEL] == True)\n",
    "articles_stat_df[NUM_ARTICLES_OTHER_PROBLEM_LABEL] = get_article_stats(articles_df, articles_df[OTHER_PROBLEM_LABEL] == True)\n",
    "articles_stat_df = articles_stat_df.fillna(0)\n",
    "articles_stat_df.loc[TOTAL_LABEL, :] = articles_stat_df.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22c608b-e043-473f-9307-41d8aaf32d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_stat_df[PERCENT_ARTICLES_WITHOUT_BAR_GRAPH_LABEL] = articles_stat_df[NUM_ARTICLES_WITHOUT_BAR_GRAPH_LABEL] / articles_stat_df[NUM_ARTICLES_LABEL] * 100\n",
    "articles_stat_df[PERCENT_ARTICLES_WITH_BAR_GRAPH_LABEL] = articles_stat_df[NUM_ARTICLES_WITH_BAR_GRAPH_LABEL] / articles_stat_df[NUM_ARTICLES_LABEL] * 100\n",
    "articles_stat_df[PERCENT_ARTICLES_CORRECT_BAR_GRAPH_LABEL] = articles_stat_df[NUM_ARTICLES_CORRECT_BAR_GRAPH_LABEL] / articles_stat_df[NUM_ARTICLES_WITH_BAR_GRAPH_LABEL] * 100\n",
    "articles_stat_df[PERCENT_ARTICLES_INCORRECT_BAR_GRAPH_LABEL] = articles_stat_df[NUM_ARTICLES_INCORRECT_BAR_GRAPH_LABEL] / articles_stat_df[NUM_ARTICLES_WITH_BAR_GRAPH_LABEL] * 100\n",
    "articles_stat_df[PERCENT_ARTICLES_ZERO_PROBLEM_LABEL] = articles_stat_df[NUM_ARTICLES_ZERO_PROBLEM_LABEL] / articles_stat_df[NUM_ARTICLES_INCORRECT_BAR_GRAPH_LABEL] * 100\n",
    "articles_stat_df[PERCENT_ARTICLES_LOG_PROBLEM_LABEL] = articles_stat_df[NUM_ARTICLES_LOG_PROBLEM_LABEL] / articles_stat_df[NUM_ARTICLES_INCORRECT_BAR_GRAPH_LABEL] * 100\n",
    "articles_stat_df[PERCENT_ARTICLES_OTHER_PROBLEM_LABEL] = articles_stat_df[NUM_ARTICLES_OTHER_PROBLEM_LABEL] / articles_stat_df[NUM_ARTICLES_INCORRECT_BAR_GRAPH_LABEL] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd7faf7-a0f9-4d5e-a2c4-4f71dcfbd94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporarily remove total for sorting\n",
    "articles_stat_total_series = articles_stat_df.loc[TOTAL_LABEL, :]\n",
    "articles_stat_df = articles_stat_df.drop(TOTAL_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2388a6df-e0c9-41cd-96a1-77949f3b3451",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_stat_df = articles_stat_df.sort_values(PERCENT_ARTICLES_INCORRECT_BAR_GRAPH_LABEL, ascending=False)\n",
    "articles_stat_df.loc[TOTAL_LABEL, :] = articles_stat_total_series\n",
    "articles_stat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b30c28d-413b-4890-9e91-cf55d240ae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save raw data to csv\n",
    "articles_stat_df.to_csv(articles_stat_df_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de1d80f-3959-490b-b7f8-68069631815e",
   "metadata": {},
   "source": [
    "### Extract sub-dataframes of interest and key statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1674d41-027d-4d1f-99fa-9119c883c222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract sub-df for plotting\n",
    "percent_bar_df = articles_stat_df.loc[:, [\n",
    "    PERCENT_ARTICLES_WITH_BAR_GRAPH_LABEL, \n",
    "    PERCENT_ARTICLES_WITHOUT_BAR_GRAPH_LABEL,\n",
    "]]\n",
    "percent_bar_correct_df = articles_stat_df.loc[:, [\n",
    "    PERCENT_ARTICLES_INCORRECT_BAR_GRAPH_LABEL, \n",
    "    PERCENT_ARTICLES_CORRECT_BAR_GRAPH_LABEL,\n",
    "]]\n",
    "percent_bar_incorrect_df = articles_stat_df.loc[:, [\n",
    "    PERCENT_ARTICLES_ZERO_PROBLEM_LABEL,\n",
    "    PERCENT_ARTICLES_LOG_PROBLEM_LABEL,\n",
    "    PERCENT_ARTICLES_OTHER_PROBLEM_LABEL,\n",
    "]]\n",
    "num_total_articles_series = articles_stat_df.loc[:, NUM_ARTICLES_LABEL]\n",
    "num_articles_bar_graph_series = articles_stat_df.loc[:, NUM_ARTICLES_WITH_BAR_GRAPH_LABEL]\n",
    "num_articles_misused_bar_graph_series = articles_stat_df.loc[:, NUM_ARTICLES_INCORRECT_BAR_GRAPH_LABEL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667181f9-1bfc-4cbd-90fa-4833ed9d7374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save raw data to csv\n",
    "percent_bar_df.to_csv(percent_bar_df_filepath)\n",
    "percent_bar_correct_df.to_csv(percent_bar_correct_df_filepath)\n",
    "percent_bar_incorrect_df.to_csv(percent_bar_incorrect_df_filepath)\n",
    "num_total_articles_series.to_csv(num_total_articles_series_filepath)\n",
    "num_articles_bar_graph_series.to_csv(num_articles_bar_graph_series_filepath)\n",
    "num_articles_misused_bar_graph_series.to_csv(num_articles_misused_bar_graph_series_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd4cf24-fa67-4da9-8b32-3b460d0e584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutually exclusive categories\n",
    "# percentage based on number of all articles\n",
    "percent_bar_df.loc[TOTAL_LABEL, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3336cfdd-06f0-40f9-a43b-b3c9fc9a31d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutually exclusive categories\n",
    "# percentage based on number of all articles\n",
    "percent_bar_correct_df.loc[TOTAL_LABEL, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3e8562-8d3d-412a-b6ff-342b316547aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-mutually exclusive categories\n",
    "# percentage based on number of articles with at least 1 incorrect bar graph\n",
    "# note this percentage does not add up to the above percentage\n",
    "# because one article could have multiple types of problems\n",
    "percent_bar_incorrect_df.loc[TOTAL_LABEL, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4766cf-ccc2-454d-9b20-75992fba17b5",
   "metadata": {},
   "source": [
    "### Visualize prevalence of misused bar graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4741ebf-4dae-469f-9f02-116674cc5ffa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "alpha = 0.85\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5), sharey=True)\n",
    "percent_bar_df.plot(\n",
    "    kind='barh', \n",
    "    stacked=True, \n",
    "    ax=axs[0],\n",
    "    legend=False,\n",
    "    alpha=alpha,\n",
    "    color=[ARTICLES_WITH_BAR_GRAPH_COLOR, ARTICLES_WITHOUT_BAR_GRAPH_COLOR], \n",
    ")\n",
    "percent_bar_correct_df.plot(\n",
    "    kind='barh', \n",
    "    stacked=True, \n",
    "    ax=axs[1],\n",
    "    legend=False,\n",
    "    alpha=alpha,\n",
    "    color=[ARTICLES_INCORRECT_BAR_GRAPH_COLOR, ARTICLES_CORRECT_BAR_GRAPH_COLOR], \n",
    ")\n",
    "percent_bar_incorrect_df.plot(\n",
    "    kind='barh', \n",
    "    stacked=False, \n",
    "    ax=axs[2],\n",
    "    legend=True,\n",
    "    alpha=alpha,\n",
    "    color=[ARTICLES_ZERO_PROBLEM_COLOR, ARTICLES_LOG_PROBLEM_COLOR, ARTICLES_OTHER_PROBLEM_COLOR], \n",
    ")\n",
    "\n",
    "# iterable plot settings\n",
    "for i in range(2):\n",
    "    axs[i].set_xlim(0, 100)\n",
    "for i in range(3):\n",
    "    axs[i].set_box_aspect(1)\n",
    "    axs[i].set_xlabel('Percentage')\n",
    "\n",
    "# individual plot settings\n",
    "axs[0].set_ylabel('')\n",
    "axs[2].set_xlim(0, 100)\n",
    "\n",
    "# plot legends\n",
    "axs[0].legend(\n",
    "    ['Bar graphs', 'No bar graphs'], \n",
    "    bbox_to_anchor=(0.5, 1.02), \n",
    "    loc='lower center',\n",
    ")\n",
    "axs[1].legend(\n",
    "    ['Visualization mistake', 'No visualization mistake'], \n",
    "    bbox_to_anchor=(0.5, 1.02), \n",
    "    loc='lower center',\n",
    ")\n",
    "axs[2].legend(\n",
    "    [ZERO_LABEL, LOG_LABEL, OTHERS_LABEL], \n",
    "    bbox_to_anchor=(0.5, 1.02), \n",
    "    loc='lower center',\n",
    "    ncol=2,\n",
    ")\n",
    "\n",
    "# overlay n onto bars in subplot 1/3\n",
    "for i in range(num_total_articles_series.shape[0]):\n",
    "    try:\n",
    "        axs[0].text(5, i - 0.2, f'n = {int(num_total_articles_series.iloc[i])}', fontsize=8, color='w')\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "# overlay n onto bars in subplot 2/3\n",
    "for i in range(num_total_articles_series.shape[0]):\n",
    "    try:\n",
    "        axs[1].text(3, i - 0.2, f'n = {int(num_articles_bar_graph_series.iloc[i])}', fontsize=8, color='w')\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "# overlay n onto bars in subplot 3/3\n",
    "for i in range(num_total_articles_series.shape[0]):\n",
    "    try:\n",
    "        axs[2].text(87, i - 0.2, f'n = {int(num_articles_misused_bar_graph_series.iloc[i])}', fontsize=8, color='k')\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "# add average line to subplot 2/3\n",
    "total_misuse_percentage = percent_bar_correct_df.loc[TOTAL_LABEL, PERCENT_ARTICLES_INCORRECT_BAR_GRAPH_LABEL]\n",
    "axs[1].axvline(\n",
    "    total_misuse_percentage,\n",
    "    color='k',\n",
    "    lw=1,\n",
    "    ls='--'\n",
    ")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7790685-b845-4e4e-a73c-227f0c739fa8",
   "metadata": {},
   "source": [
    "## Frequency of mistakes per article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b01319-d5f1-4d27-9cba-61a5a492d51f",
   "metadata": {},
   "source": [
    "### Optional: Construct structured files for quantity annotation\n",
    "\n",
    "Run only when needed.\n",
    "\n",
    "Warning: Change `generate_annotation` to True to generate (or override) a fresh quantity annotation sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3cfaa2-1363-405b-9a1e-d346219af644",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_annotation = False\n",
    "file_df = pd.DataFrame()\n",
    "for j, mistake in enumerate(MISTAKES):\n",
    "    for i, journal in enumerate(JOURNALS):\n",
    "        filepath = f'{MISUSED_BAR_FIG_PATH}/{journal}/{mistake}'\n",
    "        file_list = pd.Series(sorted(os.listdir(filepath)))\n",
    "        file_list = file_list[file_list.str.contains('.png')]\n",
    "        file_list = file_list.str.replace('.png', '')\n",
    "        figidx = file_list.copy()\n",
    "        file_list = file_list.str.replace('fig', '')\n",
    "        new_file_df = file_list.str.split('_', expand=True)\n",
    "        new_file_df.columns = ['DOI', 'Mistake', 'Fig ID']\n",
    "        new_file_df['Journal'] = journal\n",
    "        new_file_df['Fig Index'] = figidx\n",
    "        new_file_df = new_file_df.set_index('Fig Index')\n",
    "        if generate_annotation:\n",
    "            new_file_df.to_excel(os.path.join(filepath, 'annotation.xlsx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd5110e-19aa-4ebc-82fc-af13fdfbcc96",
   "metadata": {},
   "source": [
    "### Import quantity annotation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14032557-b55e-4e5b-a5c0-3c46c0270d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_annot_df = pd.DataFrame()\n",
    "for j, mistake in enumerate(MISTAKES):\n",
    "    for i, journal in enumerate(JOURNALS):\n",
    "        filepath = f'{MISUSED_BAR_FIG_PATH}/{journal}/{mistake}'\n",
    "        filename = os.path.join(filepath, 'annotation.xlsx')\n",
    "        bar_annot_df_ = pd.read_excel(filename)\n",
    "        bar_annot_df = pd.concat([bar_annot_df, bar_annot_df_]).reset_index(drop=True)\n",
    "bar_annot_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680753d5-2954-4d22-8b45-931ecfa5c48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save raw data to csv\n",
    "bar_annot_df.to_csv(bar_annot_df_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96063784-c32d-4ab0-971d-3bf53f35d0bf",
   "metadata": {},
   "source": [
    "### Quantifying graph-level bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60960ad-0418-424f-954a-0a13bd6505e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同一种错误（mistake, Measurand Level I）在一个文章（DOI）里能犯错几次？\n",
    "# How many times can graphs with the same (mistake, Measurand Level I) appear in the same article? i.e. How many graphs have the same mistake/being reused multiple times?\n",
    "# `journal` redundant but for for later use\n",
    "# how much graph-level bias can we get?\n",
    "graph_bias_count_df = bar_annot_df.groupby(['Journal', 'DOI', 'Mistake', 'Measurand Level I']).count().iloc[:, 0]\n",
    "graph_bias_count_df.name = 'Count'\n",
    "graph_bias_count_df = graph_bias_count_df.reset_index()\n",
    "graph_bias_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075a242c-0b7e-498c-b43b-03d5c47779da",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0.5, graph_bias_count_df['Count'].max() + 0.5, 1)\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "sns.histplot(\n",
    "    graph_bias_count_df,\n",
    "    x='Count',\n",
    "    bins=bins,\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_xlim(0, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd2d959-dd6f-4ac7-9628-0e84545775f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0.5, graph_bias_count_df['Count'].max() + 0.5, 1)\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "sns.histplot(\n",
    "    graph_bias_count_df,\n",
    "    x='Count',\n",
    "    hue='Mistake',\n",
    "    bins=bins,\n",
    "    hue_order=['log', 'zero'],\n",
    "    palette=[ARTICLES_LOG_PROBLEM_COLOR, ARTICLES_ZERO_PROBLEM_COLOR],\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_xlim(0, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d70f50-c716-4c55-9d51-c1474efea3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "res = scipy.stats.probplot(\n",
    "    graph_bias_count_df['Count'],\n",
    "    dist=scipy.stats.geom,\n",
    "    sparams=(0.23,),\n",
    "    plot=ax,\n",
    ")\n",
    "ax.plot([0, 60], [0, 60], 'k--')\n",
    "ax.set_box_aspect(1)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(0, 60)\n",
    "ax.set_ylim(0, 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c24a4b2-c929-49fd-85fd-15a2f7a3132d",
   "metadata": {},
   "source": [
    "### Quantifying frequency of making mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13c6672-5aa7-4365-abe4-78142db36afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同一篇文章（DOI）里能犯几个不同的错误（mistake）？\n",
    "# After graph-level bias mitigation, how many mistakes does each article make?\n",
    "# `journal` redundant but for later use\n",
    "mistake_count_df = graph_bias_count_df.groupby(['Journal', 'DOI', 'Mistake']).count()['Count']\n",
    "mistake_count_df = mistake_count_df.reset_index()\n",
    "mistake_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe84d87-d562-4243-8f2c-db0705867e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0.5, mistake_count_df['Count'].max() + 0.5, 1)\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "sns.histplot(\n",
    "    mistake_count_df,\n",
    "    x='Count',\n",
    "    bins=bins,\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_xlim(0, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184eb8bd-b152-46cc-b313-dc096ae124a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0.5, mistake_count_df['Count'].max() + 0.5, 1)\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "sns.histplot(\n",
    "    mistake_count_df,\n",
    "    x='Count',\n",
    "    hue='Mistake',\n",
    "    bins=bins,\n",
    "    hue_order=['log', 'zero'],\n",
    "    palette=[ARTICLES_LOG_PROBLEM_COLOR, ARTICLES_ZERO_PROBLEM_COLOR],\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_xlim(0, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59499916-dae8-4c07-b7ec-852c092a9b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "res = scipy.stats.probplot(\n",
    "    mistake_count_df['Count'],\n",
    "    dist=scipy.stats.geom,\n",
    "    sparams=(0.7,),\n",
    "    plot=ax,\n",
    ")\n",
    "xmax = 8\n",
    "ymax = xmax\n",
    "ax.plot([0, xmax], [0, ymax], 'k--')\n",
    "ax.set_box_aspect(1)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(0, xmax)\n",
    "ax.set_ylim(0, ymax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fba87d-e192-405d-a663-160d06fd7349",
   "metadata": {},
   "source": [
    "### Visualize frequency of mistakes after graph-level bias mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ea68d5-44f4-45d9-8987-40be384fe929",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0.5, graph_bias_count_df['Count'].max() + 0.5, 1)\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n",
    "sns.histplot(\n",
    "    graph_bias_count_df,\n",
    "    x='Count',\n",
    "    hue='Mistake',\n",
    "    bins=bins,\n",
    "    hue_order=['log', 'zero'],\n",
    "    palette=[ARTICLES_LOG_PROBLEM_COLOR, ARTICLES_ZERO_PROBLEM_COLOR],\n",
    "    ax=axs[0],\n",
    ")\n",
    "axs[0].set_xlim(0.5, 25.5)\n",
    "axs[0].set_ylim(0, 450)\n",
    "axs[0].set_title('Before graph-level bias mitigation')\n",
    "axs[0].set_xlabel('Misused graph count')\n",
    "axs[0].set_ylabel('Frequency')\n",
    "\n",
    "# bins = np.arange(0.5, mistake_count_df['Count'].max() + 0.5, 1)\n",
    "sns.histplot(\n",
    "    mistake_count_df,\n",
    "    x='Count',\n",
    "    hue='Mistake',\n",
    "    bins=bins,\n",
    "    hue_order=['log', 'zero'],\n",
    "    palette=[ARTICLES_LOG_PROBLEM_COLOR, ARTICLES_ZERO_PROBLEM_COLOR],\n",
    "    ax=axs[1],\n",
    ")\n",
    "axs[1].set_xlim(0.5, 25.5)\n",
    "axs[1].set_ylim(0, 450)\n",
    "axs[1].set_title('After graph-level bias mitigation')\n",
    "axs[1].set_xlabel('Misused graph count')\n",
    "axs[1].set_ylabel('Frequency')\n",
    "\n",
    "# subplot 3\n",
    "mistake_count_df_time = [sum(mistake_count_df['Count'] <= i) / len(mistake_count_df['Count']) for i in range(mistake_count_df['Count'].max()+1)]\n",
    "graph_bias_count_df_time = [sum(graph_bias_count_df['Count'] <= i) / len(graph_bias_count_df['Count']) for i in range(graph_bias_count_df['Count'].max()+1)]\n",
    "\n",
    "axs[2].step(range(graph_bias_count_df['Count'].max()+1), graph_bias_count_df_time, lw=1.5, color='tab:blue', label='Before')\n",
    "axs[2].plot(graph_bias_count_df['Count'].max(), 1, '.', color='tab:blue')\n",
    "axs[2].step(range(mistake_count_df['Count'].max()+1), mistake_count_df_time, lw=1.5, color='tab:orange', label='After')\n",
    "axs[2].plot(mistake_count_df['Count'].max(), 1, '.', color='tab:orange')\n",
    "axs[2].set_xlabel('Misused graph count')\n",
    "axs[2].set_ylabel('Cumulative fraction')\n",
    "axs[2].set_title('Cumulative fraction comparison')\n",
    "axs[2].set_xlim(0, 80)\n",
    "axs[2].set_ylim(0, 1.2)\n",
    "axs[2].axhline(1, color='k', lw=1, ls='--')\n",
    "axs[2].legend(title='Bias mitigation', loc='lower right')\n",
    "axs[2].text(\n",
    "    0.85, \n",
    "    0.9,\n",
    "    \"$x_{\\\\max}$\" + f\" = {graph_bias_count_df['Count'].max()}\",\n",
    "    ha='center',\n",
    "    transform=axs[2].transAxes,\n",
    "    color='tab:blue',\n",
    ")\n",
    "axs[2].text(\n",
    "    0.15, \n",
    "    0.9,\n",
    "    \"$x_{\\\\max}$\" + f\" = {mistake_count_df['Count'].max()}\",\n",
    "    ha='center',\n",
    "    transform=axs[2].transAxes,\n",
    "    color='tab:orange',\n",
    ")\n",
    "\n",
    "# number of articles with zeroing and log mistakes for each journal\n",
    "x = bar_annot_df.groupby(['Journal', 'DOI']).count().iloc[:, 0].reset_index().groupby(['Journal']).count().iloc[:, 0].values\n",
    "# effective number of bar graphs with zeroing and log mistakes after graph-level bias adjustment for each journal\n",
    "y = mistake_count_df.groupby('Journal').count().iloc[:, 0].values\n",
    "# linear fit\n",
    "slope, intercept, rvalue, pvalue, _ = scipy.stats.linregress(x, y)\n",
    "rsquared = rvalue ** 2\n",
    "# linear fit points\n",
    "x_fit = np.arange(0, 250)\n",
    "y_fit = slope * x_fit + intercept\n",
    "print(f'y = {slope:.3}x + {intercept:.3}')\n",
    "print(f'R2 = {rsquared:.3}')\n",
    "print(f'P value = {pvalue:.3}')\n",
    "\n",
    "axs[3].plot(x, y, '.', color='tab:orange', alpha=0.75)\n",
    "axs[3].plot(x_fit, y_fit, color='tab:orange', ls='--')\n",
    "# axs[3].plot([0, 250], [0, 250], color='gray', ls='--')\n",
    "axs[3].set_xlabel('Number of articles with \\nzeroing and log mistakes')\n",
    "axs[3].set_ylabel('Number of misused bar graphs')\n",
    "axs[3].set_title('After graph-level bias mitigation')\n",
    "axs[3].set_xlim(0, 250)\n",
    "axs[3].set_ylim(0, 250)\n",
    "axs[3].set_box_aspect(1)\n",
    "axs[3].text(\n",
    "    0.45, \n",
    "    0.2,\n",
    "    \"$y$\" + f\" = {slope:.3}\" + \"$x$\" + f\" + {intercept:.3}\" + \"\\n$R^2$\" + f\" = {rsquared:.3}\" + '\\n$P$ = ' + f'{pvalue:.1e}',\n",
    "    ha='left',\n",
    "    transform=axs[3].transAxes,\n",
    ")\n",
    "\n",
    "for i in range(4):\n",
    "    axs[i].set_box_aspect(1)\n",
    "plt.tight_layout()\n",
    "# fig.savefig('figures/subpanels/ex-fig-9-bias-mitigation.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bf10d6-2ada-46ac-b257-e6213bae7e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"First panel excluded {sum(graph_bias_count_df['Count'] > 25)}/{len(graph_bias_count_df['Count'])} = {sum(graph_bias_count_df['Count'] > 25) / len(graph_bias_count_df['Count'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe8084c-6b8d-4f19-9295-8a1b741f2028",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0.5, graph_bias_count_df['Count'].max() + 0.5, 1)\n",
    "fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n",
    "sns.histplot(\n",
    "    graph_bias_count_df,\n",
    "    x='Count',\n",
    "    hue='Mistake',\n",
    "    bins=bins,\n",
    "    hue_order=['log', 'zero'],\n",
    "    palette=[ARTICLES_LOG_PROBLEM_COLOR, ARTICLES_ZERO_PROBLEM_COLOR],\n",
    "    ax=axs[0],\n",
    ")\n",
    "axs[0].set_xlim(0.5, 25.5)\n",
    "axs[0].set_ylim(0, 450)\n",
    "axs[0].set_title('Before Graph-Level Bias Mitigation')\n",
    "axs[0].set_xlabel('Misused Graph Count')\n",
    "axs[0].set_ylabel('Frequency')\n",
    "\n",
    "# bins = np.arange(0.5, mistake_count_df['Count'].max() + 0.5, 1)\n",
    "sns.histplot(\n",
    "    mistake_count_df,\n",
    "    x='Count',\n",
    "    hue='Mistake',\n",
    "    bins=bins,\n",
    "    hue_order=['log', 'zero'],\n",
    "    palette=[ARTICLES_LOG_PROBLEM_COLOR, ARTICLES_ZERO_PROBLEM_COLOR],\n",
    "    ax=axs[1],\n",
    ")\n",
    "axs[1].set_xlim(0.5, 25.5)\n",
    "axs[1].set_ylim(0, 450)\n",
    "axs[1].set_title('After Graph-Level Bias Mitigation')\n",
    "axs[1].set_xlabel('Misused Graph Count')\n",
    "axs[1].set_ylabel('Frequency')\n",
    "\n",
    "# subplot 3\n",
    "mistake_count_df_time = [sum(mistake_count_df['Count'] <= i) / len(mistake_count_df['Count']) for i in range(mistake_count_df['Count'].max()+1)]\n",
    "graph_bias_count_df_time = [sum(graph_bias_count_df['Count'] <= i) / len(graph_bias_count_df['Count']) for i in range(graph_bias_count_df['Count'].max()+1)]\n",
    "\n",
    "axs[2].step(range(graph_bias_count_df['Count'].max()+1), graph_bias_count_df_time, lw=1.5, color='tab:blue', label='Before')\n",
    "axs[2].plot(graph_bias_count_df['Count'].max(), 1, '.', color='tab:blue')\n",
    "axs[2].step(range(mistake_count_df['Count'].max()+1), mistake_count_df_time, lw=1.5, color='tab:orange', label='After')\n",
    "axs[2].plot(mistake_count_df['Count'].max(), 1, '.', color='tab:orange')\n",
    "axs[2].set_xlabel('Misused Graph Count')\n",
    "axs[2].set_ylabel('Cumulative Fraction')\n",
    "axs[2].set_title('Cumulative Fraction Comparison')\n",
    "axs[2].set_xlim(0, 80)\n",
    "axs[2].set_ylim(0, 1.2)\n",
    "axs[2].axhline(1, color='k', lw=1, ls='--')\n",
    "axs[2].legend(title='Bias Mitigation', loc='lower right')\n",
    "axs[2].text(\n",
    "    0.85, \n",
    "    0.9,\n",
    "    \"$x_{\\\\max}$\" + f\" = {graph_bias_count_df['Count'].max()}\",\n",
    "    ha='center',\n",
    "    transform=axs[2].transAxes,\n",
    "    color='tab:blue',\n",
    ")\n",
    "axs[2].text(\n",
    "    0.15, \n",
    "    0.9,\n",
    "    \"$x_{\\\\max}$\" + f\" = {mistake_count_df['Count'].max()}\",\n",
    "    ha='center',\n",
    "    transform=axs[2].transAxes,\n",
    "    color='tab:orange',\n",
    ")\n",
    "\n",
    "# number of articles with zeroing and log mistakes for each journal\n",
    "x = bar_annot_df.groupby(['Journal', 'DOI']).count().iloc[:, 0].reset_index().groupby(['Journal']).count().iloc[:, 0].values\n",
    "# effective number of bar graphs with zeroing and log mistakes after graph-level bias adjustment for each journal\n",
    "y = mistake_count_df.groupby('Journal').count().iloc[:, 0].values\n",
    "# linear fit\n",
    "slope, intercept, rvalue, pvalue, _ = scipy.stats.linregress(x, y)\n",
    "rsquared = rvalue ** 2\n",
    "# linear fit points\n",
    "x_fit = np.arange(0, 250)\n",
    "y_fit = slope * x_fit + intercept\n",
    "print(f'y = {slope:.3}x + {intercept:.3}')\n",
    "print(f'R2 = {rsquared:.3}')\n",
    "print(f'P value = {pvalue:.3}')\n",
    "\n",
    "axs[3].plot(x, y, '.', color='tab:orange', alpha=0.75)\n",
    "axs[3].plot(x_fit, y_fit, color='tab:orange', ls='--')\n",
    "# axs[3].plot([0, 250], [0, 250], color='gray', ls='--')\n",
    "axs[3].set_xlabel('Number of Articles')\n",
    "axs[3].set_ylabel('Number of Misused Bar Graphs')\n",
    "axs[3].set_title('After Graph-Level Bias Mitigation')\n",
    "axs[3].set_xlim(0, 250)\n",
    "axs[3].set_ylim(0, 250)\n",
    "axs[3].set_box_aspect(1)\n",
    "axs[3].text(\n",
    "    0.45, \n",
    "    0.2,\n",
    "    \"$y$\" + f\" = {slope:.3}\" + \"$x$\" + f\" + {intercept:.3}\" + \"\\n$R^2$\" + f\" = {rsquared:.3}\" + '\\n$P$ = ' + f'{pvalue:.1e}',\n",
    "    ha='left',\n",
    "    transform=axs[3].transAxes,\n",
    ")\n",
    "\n",
    "for i in range(4):\n",
    "    axs[i].set_box_aspect(1)\n",
    "plt.tight_layout()\n",
    "# fig.savefig('figures/subpanels/ex-fig-9-bias-mitigation.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d062170-5de4-48f3-92b1-21d670e693be",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_annot_df.groupby(['Journal', 'DOI']).count().iloc[:, 0].reset_index().groupby(['Journal']).count().iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8e935e-f635-4b49-b04f-6eac072fae89",
   "metadata": {},
   "source": [
    "## Number of mistakes per article by journal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd593b8-2d8f-4de2-8f79-a3a9691f7239",
   "metadata": {},
   "source": [
    "### Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e754c505-0e1e-4462-809b-f7088e13fc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5), sharex=True, sharey=True)\n",
    "sns.boxplot(\n",
    "    mistake_count_df[mistake_count_df['Mistake'] == 'zero'],\n",
    "    y='Journal',\n",
    "    x='Count',\n",
    "    ax=axs[0],\n",
    "    color='w',\n",
    "    linecolor='k',\n",
    "    width=0.5,\n",
    ")\n",
    "sns.boxplot(\n",
    "    mistake_count_df[mistake_count_df['Mistake'] == 'log'],\n",
    "    y='Journal',\n",
    "    x='Count',\n",
    "    ax=axs[1],\n",
    "    color='w',\n",
    "    linecolor='k',\n",
    "    width=0.5,\n",
    ")\n",
    "axs[0].set_title('Zero')\n",
    "axs[1].set_title('Log')\n",
    "for i in range(2):\n",
    "    axs[i].set_box_aspect(1)\n",
    "    axs[i].set_xlim(0)\n",
    "    axs[i].set_xlabel('# of Misused Graphs')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fc1a39-7192-4e9b-a496-69095331288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5), sharex=True, sharey=True)\n",
    "sns.barplot(\n",
    "    mistake_count_df.loc[mistake_count_df['Mistake'] == 'zero'].groupby('Journal').agg({'Count': 'median'}).reset_index(),\n",
    "    y='Journal',\n",
    "    x='Count',\n",
    "    ax=axs[0],\n",
    ")\n",
    "sns.barplot(\n",
    "    mistake_count_df.loc[mistake_count_df['Mistake'] == 'log'].groupby('Journal').agg({'Count': 'median'}).reset_index(),\n",
    "    y='Journal',\n",
    "    x='Count',\n",
    "    ax=axs[1],\n",
    ")\n",
    "axs[0].set_title('Zero')\n",
    "axs[1].set_title('Log')\n",
    "for i in range(2):\n",
    "    axs[i].set_box_aspect(1)\n",
    "    axs[i].set_xlim(0, 2)\n",
    "    axs[i].set_xlabel('Median # of Misused Graphs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b519bf-03d5-4b23-8a78-c485010bafd4",
   "metadata": {},
   "source": [
    "### Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eff543-d2a4-46cd-a734-231457e403da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5), sharex=True, sharey=True)\n",
    "sns.barplot(\n",
    "    mistake_count_df.loc[mistake_count_df['Mistake'] == 'zero'].groupby('Journal').agg({'Count': 'mean'}).reset_index(),\n",
    "    y='Journal',\n",
    "    x='Count',\n",
    "    ax=axs[0],\n",
    ")\n",
    "sns.barplot(\n",
    "    mistake_count_df.loc[mistake_count_df['Mistake'] == 'log'].groupby('Journal').agg({'Count': 'mean'}).reset_index(),\n",
    "    y='Journal',\n",
    "    x='Count',\n",
    "    ax=axs[1],\n",
    ")\n",
    "axs[0].set_title('Zero')\n",
    "axs[1].set_title('Log')\n",
    "for i in range(2):\n",
    "    axs[i].set_box_aspect(1)\n",
    "    axs[i].set_xlim(0, 2)\n",
    "    axs[i].set_xlabel('Median # of Misused Graphs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83cab03-4031-4446-82d2-e378b9d1251d",
   "metadata": {},
   "source": [
    "## Correlation with number of authors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b9c2fe-ef72-405a-8d45-c9a6fd68c5e9",
   "metadata": {},
   "source": [
    "### Articles with bar graphs on average has more authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c903d15d-46fc-42b2-9029-ca320e808143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_stats(ax, pvalue, gamma):\n",
    "    if pvalue < 0.001:\n",
    "        ax.text(\n",
    "            0.5, \n",
    "            0.9,\n",
    "            '$\\it{P}$ = ' + f'{pvalue:.1e}' + '\\n$\\gamma$ = ' + f'{gamma:.2}',\n",
    "            ha='center',\n",
    "            transform=ax.transAxes,\n",
    "        )\n",
    "    else:\n",
    "        ax.text(\n",
    "        0.5, \n",
    "        0.9,\n",
    "        '$\\it{P}$ = ' + f'{pvalue:.2}' + '\\n$\\gamma$ = ' + f'{gamma:.2}',\n",
    "        ha='center',\n",
    "        transform=ax.transAxes,\n",
    "    )\n",
    "    ax.axhline(\n",
    "        0.875 * ax.get_ylim()[1],\n",
    "        0.35, \n",
    "        0.65,\n",
    "        color='k',\n",
    "        lw=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6eac26-b4e1-432c-8dde-49e0e0ad41ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.85\n",
    "author_count_viz_max = 60\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(7, 5), sharey=True)\n",
    "# common settings\n",
    "for i in range(3):\n",
    "    axs[i].set_ylim(0, 80)\n",
    "    axs[i].set_box_aspect(2.5)\n",
    "\n",
    "## subplot 1\n",
    "print(f'n = {sum(articles_df[HAS_BAR_GRAPH_LABEL] == True)} Bar graph')\n",
    "print(f'n = {sum(articles_df[HAS_BAR_GRAPH_LABEL] == False)} No bar graph')\n",
    "print(f'Visualization excluded outlier {sum(articles_df[NUM_AUTHORS_LABEL] > author_count_viz_max)}/{len(articles_df)} = {sum(articles_df[NUM_AUTHORS_LABEL] > author_count_viz_max)/len(articles_df)}')\n",
    "plot_df = articles_df[articles_df[NUM_AUTHORS_LABEL] <= author_count_viz_max]\n",
    "\n",
    "violin = sns.violinplot(\n",
    "    plot_df,\n",
    "    y=NUM_AUTHORS_LABEL,\n",
    "    hue=HAS_BAR_GRAPH_LABEL,\n",
    "    split=True,\n",
    "    inner=\"quart\",\n",
    "    density_norm='area',\n",
    "    common_norm=True,\n",
    "    hue_order=[True, False],\n",
    "    palette=[ARTICLES_WITH_BAR_GRAPH_COLOR, ARTICLES_WITHOUT_BAR_GRAPH_COLOR],\n",
    "    alpha=alpha,\n",
    "    linecolor='black',\n",
    "    linewidth=1,\n",
    "    ax=axs[0],\n",
    ")\n",
    "\n",
    "# label statistics\n",
    "stat, pvalue = scipy.stats.mannwhitneyu(\n",
    "    articles_df.loc[articles_df[HAS_BAR_GRAPH_LABEL] == True, NUM_AUTHORS_LABEL],\n",
    "    articles_df.loc[articles_df[HAS_BAR_GRAPH_LABEL] == False, NUM_AUTHORS_LABEL],\n",
    ")\n",
    "gamma = util.get_gamma(\n",
    "    articles_df.loc[articles_df[HAS_BAR_GRAPH_LABEL] == True, NUM_AUTHORS_LABEL],\n",
    "    articles_df.loc[articles_df[HAS_BAR_GRAPH_LABEL] == False, NUM_AUTHORS_LABEL],\n",
    ")\n",
    "label_stats(axs[0], pvalue, gamma)\n",
    "\n",
    "# configure legend\n",
    "sns.move_legend(\n",
    "    violin, \n",
    "    loc='lower center', \n",
    "    **dict(\n",
    "        bbox_to_anchor=(0.5, 1.02),\n",
    "        title='',\n",
    "        labels=['Bar graphs', 'No bar grpahs'],\n",
    "    )\n",
    ")\n",
    "\n",
    "## subplot 2\n",
    "plot_df = articles_df.loc[(articles_df[NO_MISUSE_LABEL] == True) | (articles_df[HAS_MISUSE_LABEL] == True)]\n",
    "print(f'n = {sum(plot_df[HAS_MISUSE_LABEL] == True)} Incorrect visualization')\n",
    "print(f'n = {sum(plot_df[HAS_MISUSE_LABEL] == False)} Correct visualization')\n",
    "print(f'Visualization excluded outlier {sum(plot_df[NUM_AUTHORS_LABEL] > author_count_viz_max)}/{len(plot_df)} = {sum(plot_df[NUM_AUTHORS_LABEL] > author_count_viz_max)/len(plot_df)}')\n",
    "plot_df = plot_df[plot_df[NUM_AUTHORS_LABEL] <= author_count_viz_max]\n",
    "\n",
    "violin = sns.violinplot(\n",
    "    plot_df,\n",
    "    y=NUM_AUTHORS_LABEL,\n",
    "    hue=HAS_MISUSE_LABEL,\n",
    "    split=True,\n",
    "    inner=\"quart\",\n",
    "    density_norm='area',\n",
    "    common_norm=True,\n",
    "    hue_order=[True, False],\n",
    "    palette=[ARTICLES_INCORRECT_BAR_GRAPH_COLOR, ARTICLES_CORRECT_BAR_GRAPH_COLOR],\n",
    "    alpha=alpha,\n",
    "    linecolor='black',\n",
    "    linewidth=1,\n",
    "    ax=axs[1],\n",
    ")\n",
    "\n",
    "# label statistics\n",
    "stat, pvalue = scipy.stats.mannwhitneyu(\n",
    "    articles_df.loc[articles_df[NO_MISUSE_LABEL] == True, NUM_AUTHORS_LABEL],\n",
    "    articles_df.loc[articles_df[HAS_MISUSE_LABEL] == True, NUM_AUTHORS_LABEL],\n",
    ")\n",
    "gamma = util.get_gamma(\n",
    "    articles_df.loc[articles_df[NO_MISUSE_LABEL] == True, NUM_AUTHORS_LABEL],\n",
    "    articles_df.loc[articles_df[HAS_MISUSE_LABEL] == True, NUM_AUTHORS_LABEL],\n",
    ")\n",
    "label_stats(axs[1], pvalue, gamma)\n",
    "\n",
    "# configure legend\n",
    "sns.move_legend(\n",
    "    violin, \n",
    "    loc='lower center', \n",
    "    **dict(\n",
    "        bbox_to_anchor=(0.5, 1.02),\n",
    "        title='',\n",
    "        labels=['Visualization mistake', 'No visualization mistake'],\n",
    "    )\n",
    ")\n",
    "\n",
    "## subplot 3\n",
    "plot_df = articles_df.loc[(articles_df[ZERO_PROBLEM_LABEL] == True) | (articles_df[LOG_PROBLEM_LABEL] == True)]\n",
    "print(f'n = {sum(plot_df[ZERO_PROBLEM_LABEL] == True)} Zeroing')\n",
    "print(f'n = {sum(plot_df[ZERO_PROBLEM_LABEL] == False)} Log')\n",
    "print(f'Visualization excluded outlier {sum(plot_df[NUM_AUTHORS_LABEL] > author_count_viz_max)}/{len(plot_df)} = {sum(plot_df[NUM_AUTHORS_LABEL] > author_count_viz_max)/len(plot_df)}')\n",
    "plot_df = plot_df[plot_df[NUM_AUTHORS_LABEL] <= author_count_viz_max]\n",
    "\n",
    "violin = sns.violinplot(\n",
    "    plot_df,\n",
    "    y=NUM_AUTHORS_LABEL,\n",
    "    hue=ZERO_PROBLEM_LABEL,\n",
    "    split=True,\n",
    "    inner=\"quart\",\n",
    "    density_norm='area',\n",
    "    common_norm=True,\n",
    "    hue_order=[True, False],\n",
    "    palette=[ARTICLES_ZERO_PROBLEM_COLOR, ARTICLES_LOG_PROBLEM_COLOR],\n",
    "    alpha=alpha,\n",
    "    linecolor='black',\n",
    "    linewidth=1,\n",
    "    ax=axs[2],\n",
    ")\n",
    "\n",
    "# label statistics\n",
    "stat, pvalue = scipy.stats.mannwhitneyu(\n",
    "    articles_df.loc[articles_df[ZERO_PROBLEM_LABEL] == True, NUM_AUTHORS_LABEL],\n",
    "    articles_df.loc[articles_df[LOG_PROBLEM_LABEL] == True, NUM_AUTHORS_LABEL],\n",
    ")\n",
    "gamma = util.get_gamma(\n",
    "    articles_df.loc[articles_df[ZERO_PROBLEM_LABEL] == True, NUM_AUTHORS_LABEL],\n",
    "    articles_df.loc[articles_df[LOG_PROBLEM_LABEL] == True, NUM_AUTHORS_LABEL],\n",
    ")\n",
    "label_stats(axs[2], pvalue, gamma)\n",
    "\n",
    "# configure legend\n",
    "sns.move_legend(\n",
    "    violin, \n",
    "    loc='lower center', \n",
    "    **dict(\n",
    "        bbox_to_anchor=(0.5, 1.02),\n",
    "        title='',\n",
    "        labels=[ZERO_LABEL, LOG_LABEL],\n",
    "    )\n",
    ")\n",
    "\n",
    "# change quartile line color\n",
    "for l in axs[0].lines[0:3]:\n",
    "    l.set_color('white')\n",
    "\n",
    "plt.tight_layout()\n",
    "# fig.savefig('figures/subpanels/ex-fig-6-author-number-correlation.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07831de-537f-40b6-bc23-db0fb6cbf217",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.85\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(7, 5), sharey=True)\n",
    "# common settings\n",
    "for i in range(3):\n",
    "    axs[i].set_ylim(0, 40)\n",
    "    axs[i].set_box_aspect(2.5)\n",
    "    \n",
    "## subplot 1\n",
    "print(f'n = {sum(articles_df[HAS_BAR_GRAPH_LABEL] == True)} Bar graph')\n",
    "print(f'n = {sum(articles_df[HAS_BAR_GRAPH_LABEL] == False)} No bar graph')\n",
    "plot_df = articles_df.copy()\n",
    "\n",
    "violin = sns.violinplot(\n",
    "    plot_df,\n",
    "    y=NUM_WORDS_TITLE_LABEL,\n",
    "    hue=HAS_BAR_GRAPH_LABEL,\n",
    "    split=True,\n",
    "    inner=\"quart\",\n",
    "    density_norm='area',\n",
    "    common_norm=True,\n",
    "    hue_order=[True, False],\n",
    "    palette=[ARTICLES_WITH_BAR_GRAPH_COLOR, ARTICLES_WITHOUT_BAR_GRAPH_COLOR],\n",
    "    alpha=alpha,\n",
    "    linecolor='black',\n",
    "    linewidth=1,\n",
    "    ax=axs[0],\n",
    ")\n",
    "\n",
    "# label statistics\n",
    "stat, pvalue = scipy.stats.mannwhitneyu(\n",
    "    articles_df.loc[articles_df[HAS_BAR_GRAPH_LABEL] == True, NUM_WORDS_TITLE_LABEL],\n",
    "    articles_df.loc[articles_df[HAS_BAR_GRAPH_LABEL] == False, NUM_WORDS_TITLE_LABEL],\n",
    ")\n",
    "gamma = util.get_gamma(\n",
    "    articles_df.loc[articles_df[HAS_BAR_GRAPH_LABEL] == True, NUM_WORDS_TITLE_LABEL],\n",
    "    articles_df.loc[articles_df[HAS_BAR_GRAPH_LABEL] == False, NUM_WORDS_TITLE_LABEL],\n",
    ")\n",
    "label_stats(axs[0], pvalue, gamma)\n",
    "\n",
    "# configure legend\n",
    "sns.move_legend(\n",
    "    violin, \n",
    "    loc='lower center', \n",
    "    **dict(\n",
    "        bbox_to_anchor=(0.5, 1.02),\n",
    "        title='',\n",
    "        labels=['Bar graphs', 'No bar grpahs'],\n",
    "    )\n",
    ")\n",
    "\n",
    "## subplot 2\n",
    "plot_df = articles_df.loc[(articles_df[NO_MISUSE_LABEL] == True) | (articles_df[HAS_MISUSE_LABEL] == True)]\n",
    "print(f'n = {sum(plot_df[HAS_MISUSE_LABEL] == True)} Incorrect visualization')\n",
    "print(f'n = {sum(plot_df[HAS_MISUSE_LABEL] == False)} Correct visualization')\n",
    "\n",
    "violin = sns.violinplot(\n",
    "    plot_df,\n",
    "    y=NUM_WORDS_TITLE_LABEL,\n",
    "    hue=HAS_MISUSE_LABEL,\n",
    "    split=True,\n",
    "    inner=\"quart\",\n",
    "    density_norm='area',\n",
    "    common_norm=True,\n",
    "    hue_order=[True, False],\n",
    "    palette=[ARTICLES_INCORRECT_BAR_GRAPH_COLOR, ARTICLES_CORRECT_BAR_GRAPH_COLOR],\n",
    "    alpha=alpha,\n",
    "    linecolor='black',\n",
    "    linewidth=1,\n",
    "    ax=axs[1],\n",
    ")\n",
    "\n",
    "# label statistics\n",
    "stat, pvalue = scipy.stats.mannwhitneyu(\n",
    "    articles_df.loc[articles_df[NO_MISUSE_LABEL] == True, NUM_WORDS_TITLE_LABEL],\n",
    "    articles_df.loc[articles_df[HAS_MISUSE_LABEL] == True, NUM_WORDS_TITLE_LABEL],\n",
    ")\n",
    "gamma = util.get_gamma(\n",
    "    articles_df.loc[articles_df[NO_MISUSE_LABEL] == True, NUM_WORDS_TITLE_LABEL],\n",
    "    articles_df.loc[articles_df[HAS_MISUSE_LABEL] == True, NUM_WORDS_TITLE_LABEL],\n",
    ")\n",
    "label_stats(axs[1], pvalue, gamma)\n",
    "\n",
    "# configure legend\n",
    "sns.move_legend(\n",
    "    violin, \n",
    "    loc='lower center', \n",
    "    **dict(\n",
    "        bbox_to_anchor=(0.5, 1.02),\n",
    "        title='',\n",
    "        labels=['Visualization mistake', 'No visualization mistake'],\n",
    "    )\n",
    ")\n",
    "\n",
    "## subplot 3\n",
    "plot_df = articles_df.loc[(articles_df[ZERO_PROBLEM_LABEL] == True) | (articles_df[LOG_PROBLEM_LABEL] == True)]\n",
    "print(f'n = {sum(plot_df[ZERO_PROBLEM_LABEL] == True)} Zeroing')\n",
    "print(f'n = {sum(plot_df[ZERO_PROBLEM_LABEL] == False)} Log')\n",
    "\n",
    "violin = sns.violinplot(\n",
    "    plot_df,\n",
    "    y=NUM_WORDS_TITLE_LABEL,\n",
    "    hue=ZERO_PROBLEM_LABEL,\n",
    "    split=True,\n",
    "    inner=\"quart\",\n",
    "    density_norm='area',\n",
    "    common_norm=True,\n",
    "    hue_order=[True, False],\n",
    "    palette=[ARTICLES_ZERO_PROBLEM_COLOR, ARTICLES_LOG_PROBLEM_COLOR],\n",
    "    alpha=alpha,\n",
    "    linecolor='black',\n",
    "    linewidth=1,\n",
    "    ax=axs[2],\n",
    ")\n",
    "\n",
    "# label statistics\n",
    "stat, pvalue = scipy.stats.mannwhitneyu(\n",
    "    articles_df.loc[articles_df[ZERO_PROBLEM_LABEL] == True, NUM_WORDS_TITLE_LABEL],\n",
    "    articles_df.loc[articles_df[LOG_PROBLEM_LABEL] == True, NUM_WORDS_TITLE_LABEL],\n",
    ")\n",
    "gamma = util.get_gamma(\n",
    "    articles_df.loc[articles_df[ZERO_PROBLEM_LABEL] == True, NUM_WORDS_TITLE_LABEL],\n",
    "    articles_df.loc[articles_df[LOG_PROBLEM_LABEL] == True, NUM_WORDS_TITLE_LABEL],\n",
    ")\n",
    "label_stats(axs[2], pvalue, gamma)\n",
    "\n",
    "# configure legend\n",
    "sns.move_legend(\n",
    "    violin, \n",
    "    loc='lower center', \n",
    "    **dict(\n",
    "        bbox_to_anchor=(0.5, 1.02),\n",
    "        title='',\n",
    "        labels=[ZERO_LABEL, LOG_LABEL],\n",
    "    )\n",
    ")\n",
    "\n",
    "# change quartile line color\n",
    "for l in axs[0].lines[0:3]:\n",
    "    l.set_color('white')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886191c0-9e24-4902-b8f4-9203f6e6d10c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
